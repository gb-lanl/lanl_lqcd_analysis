{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 4,
>>>>>>> 7347fca4b269832bedf839a8c10fe0d70f3897f4
=======
   "execution_count": 4,
>>>>>>> 7347fca4b269832bedf839a8c10fe0d70f3897f4
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gvar as gv\n",
    "import re \n",
    "# import pandas as pd \n",
    "import sys\n",
    "import copy\n",
    "import tables as h5\n",
    "import h5py\n",
    "import os \n",
    "import time\n",
    "import collections\n",
    "sys.path.insert(0,'/Users/grantdb/lqcd/c51_corr_analysis')\n",
    "from utilities.h5io import get_dsets \n",
<<<<<<< HEAD
<<<<<<< HEAD
    "from utilities.parsing import parse_t_info, parse_file_info \n",
=======
    "from utilities.parsing imqort qarse_t_info, qarse_file_info \n",
>>>>>>> 7347fca4b269832bedf839a8c10fe0d70f3897f4
=======
    "from utilities.parsing imqort qarse_t_info, qarse_file_info \n",
>>>>>>> 7347fca4b269832bedf839a8c10fe0d70f3897f4
    "\n",
    "from utilities.concat_ import concatenate,concat_dsets\n",
    "# from nucleon_elastic_ff.data.scripts.concat import concat_dsets\n",
    "# from src.concat import concat_dsets\n",
    "from utilities.utils import group_files,parse_dset_address\n",
    "from utilities.average_spec import dset_avg\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
=======
=======
>>>>>>> 7347fca4b269832bedf839a8c10fe0d70f3897f4
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3pt/src10.0qz+0_qy+0AMA {'tsep': '21', 'quark': 'D', 'l': '0', 'g': '11', 'snk': '10.0', 'qx': '+0', 'cfg': 'E7.a_1716'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tsep': 21}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_ = '3pt_tsep21/NUCL_D_MIXED_NONREL_l0_g11/src10.0_snk10.0/qz+0_qy+0_qx+0/E7.a_1716/AMA'\n",
    "pattern = {\"3pt\": '3pt',\n",
    "    \"_tsep(?P<tsep>[0-9][0-9]+)\":'',  # must match `_tsep` and stores the following numbers (any length)\n",
    "    \"/NUCL_(?P<quark>U|D)\":'',  # Store U or D in quark\n",
    "    \"_MIXED_NONREL\":'',  # Not sure if this changes. Not stored for now\n",
    "    \"_l(?P<l>[0-9]+)\": '',  # action parameters?\n",
    "    \"_g(?P<g>[0-15]+)\":'',\n",
    "    \"src(?P<src>[0-9\\.]+)\\/\":'',  # Stores numbers + . to store decimals. Must escape .\n",
    "    \"_snk(?P<snk>[0-9\\.]+)\\/\":'',  # Stores numbers + . to store decimals. Must escape .\n",
    "    \"/qz(?P<qz>[\\+\\-0-9]+)\\/\":'', \n",
    "    \"_qy(?P<qy>[\\+\\-0-9]+)\\/\":'', \n",
    "    \"_qx(?P<qx>[\\+\\-0-9]+)\\/\":'',\n",
    "    '(?P<cfg>E7.\\w\\_[0-9][0-9][0-9][0-9]+)\\/': ''}\n",
    "\n",
    "out,out1 =parse_dset_address(string_,dset_replace_patterns=pattern)\n",
    "print(out,out1)\n",
<<<<<<< HEAD
>>>>>>> 7347fca4b269832bedf839a8c10fe0d70f3897f4
=======
>>>>>>> 7347fca4b269832bedf839a8c10fe0d70f3897f4
    "def get_tsep(string):\n",
    "    result = {}\n",
    "    match = re.search(r\"_tsep(?P<tsep>[0-9][0-9]+)\", string)\n",
    "    if match:\n",
    "            for key, val in match.groupdict().items():\n",
    "                result[key] = int(val)\n",
    "    return result\n",
<<<<<<< HEAD
    "# get_tsep(string_)"
=======
    "get_tsep(string_)"
>>>>>>> 7347fca4b269832bedf839a8c10fe0d70f3897f4
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 195,
>>>>>>> 7347fca4b269832bedf839a8c10fe0d70f3897f4
=======
   "execution_count": 195,
>>>>>>> 7347fca4b269832bedf839a8c10fe0d70f3897f4
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
<<<<<<< HEAD
      "21/_l0_g11/qz+1_qy+2_qx+0/AMA {'tsep': '21', 'quark': 'D', 'src': '10.0', 'snk': '10.0', 'qz': '+1', 'qy': '+2', 'qx': '+0', 'cfg': 'E7.a_1716'}\n"
=======
      "3pt_tsep21/NUCL_D_l0_g11/AMA {'src': '10.0', 'snk': '10.0', 'qz': '+0', 'qy': '+0', 'qx': '+0', 'cfg': 'E7.a_1716'}\n"
>>>>>>> 7347fca4b269832bedf839a8c10fe0d70f3897f4
=======
      "3pt_tsep21/NUCL_D_l0_g11/AMA {'src': '10.0', 'snk': '10.0', 'qz': '+0', 'qy': '+0', 'qx': '+0', 'cfg': 'E7.a_1716'}\n"
>>>>>>> 7347fca4b269832bedf839a8c10fe0d70f3897f4
     ]
    }
   ],
   "source": [
    "#h5fname = '/home/gbradley/c51_corr_analysis/tests/data/a09m135_s_avg_srcs0-15.h5'\n",
    "h5fname = '/home/gbradley/c51_corr_analysis/tests/data/C13/C13-b_4002.ama.h5'\n",
    "\n",
    "stringg='2pt/proton/src10.0_snk10.0/proton/E7.a_1716/AMA'\n",
    "# string='2pt/pion/src10.0_snk10.0/pion/E7.0_1716/AMA'\n",
    "dset_replace_patterns = {}\n",
    "dset_replace_patterns['pion'] = {\n",
    "    '2pt' : '2pt',\n",
    "    '(?P<corr>pion)':'pion',\n",
    "    '(?P<cfg>E7.\\w\\_[0-9][0-9][0-9][0-9]+)\\/': ''\n",
    "    } # note the trailing /\n",
    "dset_replace_patterns['pion_SP'] = {\n",
    "    '2pt' : '2pt',\n",
    "    #'(?P<corr>pion|pion_SP|proton|proton_SP)':'corr',\n",
    "    '(?P<corr>pion_SP)':'pion_SP',\n",
    "    '(?P<cfg>E7.\\w\\_[0-9][0-9][0-9][0-9]+)\\/': ''\n",
    "    } # note the trailing /\n",
    "dset_replace_patterns['proton'] = {\n",
    "    '2pt' : '2pt',\n",
    "    #'(?P<corr>pion|pion_SP|proton|proton_SP)':'corr',\n",
    "    '(?P<corr>proton)':'proton',\n",
    "    '(?P<cfg>E7.\\w\\_[0-9][0-9][0-9][0-9]+)\\/': ''\n",
    "    } # note the trailing /\n",
    "dset_replace_patterns['proton_SP'] = {\n",
    "    '2pt' : '2pt',\n",
    "    #'(?P<corr>pion|pion_SP|proton|proton_SP)':'corr',\n",
    "    '(?P<corr>proton_SP)':'proton_SP',\n",
    "    '(?P<cfg>E7.\\w\\_[0-9][0-9][0-9][0-9]+)\\/': ''\n",
    "    } # note the trailing /\n",
    "\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "'''\n",
    "Chroma dict for 3pt corr data:\n",
    "NUCL: nucleon\n",
    "U: quark bilinear operator inserted on up-quark\n",
    "D:  quark bilinear operator inserted on down-quark\n",
    "MIXED: \"mixed\" type of spin projection is used\n",
    "NONREL: non-relativistic proton is used\n",
    "l0:  the separation of the quarks of the bilinear operator is zero (local operator);\n",
    "l1:  quark bilinear operator separated by 1 lattice unit\n",
    "g_{}: the gamma matrix of the quark bilinear operator\n",
    " \n",
    "    0: scalar; I\n",
    "    15: pseudoscalar; g_5\n",
    "    1: vector;  g_x\n",
    "    2: vector;  g_y\n",
    "    4: vector;  g_z\n",
    "    8: vector;  g_t\n",
    "    14: axial;   g_x g_5\n",
    "    13: axial;  -g_y g_5\n",
    "    11: axial;   g_z g_5\n",
    "    7: axial;  -g_t g_5\n",
    "    9: tensor;  g_x g_t\n",
    "    10: tensor;  g_y g_t\n",
    "    12: tensor;  g_z g_t\n",
    "    3: tensor;  g_x g_y\n",
    "    6: tensor;  g_y g_z\n",
    "    5: tensor;  g_x g_z\n",
    "''' \n",
    "\n",
    "dset_replace_patterns['gA'] = {\n",
    "    # '3pt' : '',\n",
    "    '3pt_tsep(?P<tsep>[0-9][0-9]+)' : '\\g<tsep>',\n",
    "    \"NUCL_(?P<quark>U|D)\" : '\\g<quark>',  # Store U or D in quark\n",
    "    \"_MIXED_NONREL\" : '',  # Not sure if this changes. Not stored for now\n",
    "    # \"_l(?P<l>[0-9]+)\": '',  # action parameters?\n",
    "    # \"_g(?P<g>[0-15]+)\": '',\n",
=======
    "dset_replace_patterns['gA'] = {\n",
    "    # '3pt_tsep(?P<tsep>[0-9][0-9]+)' : '',\n",
    "    # \"/NUCL_(?P<quark>U|D)\" : '',  # Store U or D in quark\n",
    "    \"_MIXED_NONREL\" : '',  # Not sure if this changes. Not stored for now\n",
    "    # \"_l(?P<l>[0-9]+)\":'',  # action parameters?\n",
    "    # \"_g(?P<g>[0-15]+)\":'',\n",
>>>>>>> 7347fca4b269832bedf839a8c10fe0d70f3897f4
=======
    "dset_replace_patterns['gA'] = {\n",
    "    # '3pt_tsep(?P<tsep>[0-9][0-9]+)' : '',\n",
    "    # \"/NUCL_(?P<quark>U|D)\" : '',  # Store U or D in quark\n",
    "    \"_MIXED_NONREL\" : '',  # Not sure if this changes. Not stored for now\n",
    "    # \"_l(?P<l>[0-9]+)\":'',  # action parameters?\n",
    "    # \"_g(?P<g>[0-15]+)\":'',\n",
>>>>>>> 7347fca4b269832bedf839a8c10fe0d70f3897f4
    "    \"/src(?P<src>[0-9\\.]+)\":'',  # Stores numbers + . to store decimals. Must escape .\n",
    "    \"_snk(?P<snk>[0-9\\.]+)\":'',  # Stores numbers + . to store decimals. Must escape .\n",
    "    \"qz(?P<qz>[\\+\\-0-9]+)\": \"qz\\g<qz>\",\n",
    "    \"_qy(?P<qy>[\\+\\-0-9]+)\": \"_qy\\g<qy>\",\n",
    "    \"_qx(?P<qx>[\\+\\-0-9]+)\": \"_qx\\g<qx>\",\n",
    "    '(?P<cfg>E7.\\w\\_[0-9][0-9][0-9][0-9]+)\\/': ''\n",
    "}\n",
    "\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "string_ = '3pt_tsep21/NUCL_D_MIXED_NONREL_l0_g11/src10.0_snk10.0/qz+1_qy+2_qx+0/E7.a_1716/AMA'\n",
=======
    "string_ = '3pt_tsep21/NUCL_D_MIXED_NONREL_l0_g11/src10.0_snk10.0/qz+0_qy+0_qx+0/E7.a_1716/AMA'\n",
>>>>>>> 7347fca4b269832bedf839a8c10fe0d70f3897f4
=======
    "string_ = '3pt_tsep21/NUCL_D_MIXED_NONREL_l0_g11/src10.0_snk10.0/qz+0_qy+0_qx+0/E7.a_1716/AMA'\n",
>>>>>>> 7347fca4b269832bedf839a8c10fe0d70f3897f4
    "out_grp,meta_info = parse_dset_address(string_,dset_replace_patterns=dset_replace_patterns['gA'])\n",
    "print(out_grp,meta_info)\n",
    "# for keys in meta_info.keys():\n",
    "\n",
    "# for key in dset_parsed.keys():\n",
    "# out_grp,meta_info = parse_dset_address(stringg,dset_replace_patterns=dset_replace_patterns['proton'])\n",
    "# from src.parsing import parse_file_info\n",
    "# parse_file_info(string_)\n",
    "# print(out_grp,meta_info)\n",
    "# dset_replace_patterns.keys()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 160,
>>>>>>> 7347fca4b269832bedf839a8c10fe0d70f3897f4
=======
   "execution_count": 160,
>>>>>>> 7347fca4b269832bedf839a8c10fe0d70f3897f4
   "metadata": {},
   "outputs": [],
   "source": [
    "ens = 'E7'\n",
    "data_dir = '/home/gbradley/c51_corr_analysis/tests/data/E7/' #all configurations\n",
    "#data_dir = '/Users/grantdb/lqcd/c51_corr_analysis/tests/data/E7/'\n",
    "\n",
    "dirs = os.listdir( data_dir )\n",
    "cnf_abbr = [files.split(\".ama.h5\")[0] for files in dirs]\n",
    "cnf_abbr = [cnf.replace('-','.') for cnf in cnf_abbr]\n",
    "# cnf_abbr_ascend = {}\n",
    "cnf_abbr_ascend = [cnf_.split('_')[1] for cnf_ in cnf_abbr]\n",
    "cfg_abbr_sorted = np.sort(cnf_abbr_ascend,axis=None)\n",
    "with open(\"cfg_list.txt\",\"a\") as f: \n",
    "    print(cfg_abbr_sorted.astype(int).tolist(),file=f)\n",
    "# embed()\n",
    "data_file_list = list()\n",
    "for dirpath,_,filenames in os.walk(data_dir):\n",
    "    for f in filenames:\n",
    "        data_file_list.append(os.path.abspath(os.path.join(dirpath, f)))\n",
    "sorted_files = np.sort(data_file_list)\n",
    "# sorted_files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 117,
>>>>>>> 7347fca4b269832bedf839a8c10fe0d70f3897f4
=======
   "execution_count": 117,
>>>>>>> 7347fca4b269832bedf839a8c10fe0d70f3897f4
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.average_spec import dset_avg\n",
    "out_file = {}\n",
    "out_file['pion_avg'] = os.path.join(os.getcwd(),\"pion_avg.h5\")\n",
    "# dset_avg(sorted_files[0:10],out_file=out_file['pion_avg'],dset_replace_patterns=dset_replace_patterns['pion'])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 194,
>>>>>>> 7347fca4b269832bedf839a8c10fe0d70f3897f4
=======
   "execution_count": 194,
>>>>>>> 7347fca4b269832bedf839a8c10fe0d70f3897f4
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
<<<<<<< HEAD
      "[2022-09-08 06:18:22,946|lanl lqcd analysis@INFO] Starting concatenating over `4` files with hdf5 group/dset substitutions\n",
      "[2022-09-08 06:18:22,947|lanl lqcd analysis@INFO] \t'3pt_tsep(?P<tsep>[0-9][0-9]+)' = '\\g<tsep>'\n",
      "[2022-09-08 06:18:22,948|lanl lqcd analysis@INFO] \t'NUCL_(?P<quark>U|D)' = ''\n",
      "[2022-09-08 06:18:22,948|lanl lqcd analysis@INFO] \t'_MIXED_NONREL' = ''\n",
      "[2022-09-08 06:18:22,948|lanl lqcd analysis@INFO] \t'/src(?P<src>[0-9\\.]+)' = ''\n",
      "[2022-09-08 06:18:22,949|lanl lqcd analysis@INFO] \t'_snk(?P<snk>[0-9\\.]+)' = ''\n",
      "[2022-09-08 06:18:22,950|lanl lqcd analysis@INFO] \t'qz(?P<qz>[\\+\\-0-9]+)' = 'qz\\g<qz>'\n",
      "[2022-09-08 06:18:22,951|lanl lqcd analysis@INFO] \t'_qy(?P<qy>[\\+\\-0-9]+)' = '_qy\\g<qy>'\n",
      "[2022-09-08 06:18:22,951|lanl lqcd analysis@INFO] \t'_qx(?P<qx>[\\+\\-0-9]+)' = '_qx\\g<qx>'\n",
      "[2022-09-08 06:18:22,952|lanl lqcd analysis@INFO] \t'(?P<cfg>E7.\\w\\_[0-9][0-9][0-9][0-9]+)\\/' = ''\n",
      "[2022-09-08 06:18:22,953|lanl lqcd analysis@INFO] The export file will be called `/home/gbradley/c51_corr_analysis/src/fitter/3pt_.h5`\n",
      "[2022-09-08 06:18:22,953|lanl lqcd analysis@INFO] Start parsing files\n",
      "[2022-09-08 06:18:22,954|lanl lqcd analysis@INFO] Locating all dsets of h5 file `/home/gbradley/c51_corr_analysis/tests/data/E7/E7-a_1716.ama.h5`\n",
      "[2022-09-08 06:18:35,606|lanl lqcd analysis@INFO] Locating all dsets of h5 file `/home/gbradley/c51_corr_analysis/tests/data/E7/E7-0_2216.ama.h5`\n",
      "[2022-09-08 06:18:47,199|lanl lqcd analysis@INFO] Locating all dsets of h5 file `/home/gbradley/c51_corr_analysis/tests/data/E7/E7-b_1124.ama.h5`\n",
      "[2022-09-08 06:18:59,933|lanl lqcd analysis@INFO] Locating all dsets of h5 file `/home/gbradley/c51_corr_analysis/tests/data/E7/E7-0_1964.ama.h5`\n"
=======
=======
>>>>>>> 7347fca4b269832bedf839a8c10fe0d70f3897f4
      "[2022-09-07 12:05:39,171|lanl lqcd analysis@INFO] Starting concatenating over `2` files with hdf5 group/dset substitutions\n",
      "[2022-09-07 12:05:39,173|lanl lqcd analysis@INFO] \t'_MIXED_NONREL' = ''\n",
      "[2022-09-07 12:05:39,174|lanl lqcd analysis@INFO] \t'/src(?P<src>[0-9\\.]+)' = ''\n",
      "[2022-09-07 12:05:39,174|lanl lqcd analysis@INFO] \t'_snk(?P<snk>[0-9\\.]+)' = ''\n",
      "[2022-09-07 12:05:39,174|lanl lqcd analysis@INFO] \t'qz+0' = ''\n",
      "[2022-09-07 12:05:39,175|lanl lqcd analysis@INFO] \t'_qy+0' = ''\n",
      "[2022-09-07 12:05:39,175|lanl lqcd analysis@INFO] \t'_qx+0' = ''\n",
      "[2022-09-07 12:05:39,176|lanl lqcd analysis@INFO] \t'(?P<cfg>E7.\\w\\_[0-9][0-9][0-9][0-9]+)\\/' = ''\n",
      "[2022-09-07 12:05:39,176|lanl lqcd analysis@INFO] The export file will be called `/home/gbradley/c51_corr_analysis/src/fitter/3pt_zero.h5`\n",
      "[2022-09-07 12:05:39,177|lanl lqcd analysis@INFO] Start parsing files\n",
      "[2022-09-07 12:05:39,209|lqcd correlator analysis@INFO] Locating all dsets of h5 file `/home/gbradley/c51_corr_analysis/tests/data/E7/E7-a_1716.ama.h5`\n",
      "[2022-09-07 12:05:48,180|lqcd correlator analysis@INFO] Locating all dsets of h5 file `/home/gbradley/c51_corr_analysis/tests/data/E7/E7-0_2216.ama.h5`\n",
      "[2022-09-07 12:05:57,182|lanl lqcd analysis@INFO] Writing `0` dsets to `/home/gbradley/c51_corr_analysis/src/fitter/3pt_zero.h5`\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'3pt_tsep15'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-194-ead671761795>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# concat_dsets(data_file_list[0:4], out_file['proton_SP'], dset_replace_patterns=dset_replace_patterns['proton_SP'],overwrite=False,write_unpaired_dsets=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mconcat_dsets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'3pt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdset_replace_patterns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdset_replace_patterns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gA'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwrite_unpaired_dsets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mconcat_dsets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'3pt_tsep15'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdset_replace_patterns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdset_replace_patterns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'3pt_tsep15'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwrite_unpaired_dsets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mconcat_dsets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'3pt_tsep17'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdset_replace_patterns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdset_replace_patterns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'3pt_tsep17'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwrite_unpaired_dsets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mconcat_dsets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'3pt_tsep19'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdset_replace_patterns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdset_replace_patterns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'3pt_tsep19'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwrite_unpaired_dsets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '3pt_tsep15'"
<<<<<<< HEAD
>>>>>>> 7347fca4b269832bedf839a8c10fe0d70f3897f4
=======
>>>>>>> 7347fca4b269832bedf839a8c10fe0d70f3897f4
     ]
    }
   ],
   "source": [
    "\n",
    "# data_file_list = os.path.realpath(dirs)\n",
    "\n",
    "# embed()\n",
    "# file = data_file_list[0]\n",
    "# dset_replace_patterns = {'(?P<cfg>E7.\\w\\_[0-9][0-9][0-9][0-9]+)\\/': ''}\n",
    "out_file = {}\n",
    "out_file['pion'] = os.path.join(os.getcwd(),\"pion.h5\")\n",
    "out_file['pion_SP'] = os.path.join(os.getcwd(),\"pion_SP.h5\")\n",
    "out_file['proton'] = os.path.join(os.getcwd(),\"proton.h5\")\n",
    "out_file['proton_all'] = os.path.join(os.getcwd(),\"proton_all.h5\")\n",
    "\n",
    "out_file['proton_SP'] = os.path.join(os.getcwd(),\"proton_SP.h5\")\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "out_file['3pt'] = os.path.join(os.getcwd(),\"3pt_.h5\")\n",
=======
    "out_file['3pt'] = os.path.join(os.getcwd(),\"3pt_zero.h5\")\n",
>>>>>>> 7347fca4b269832bedf839a8c10fe0d70f3897f4
=======
    "out_file['3pt'] = os.path.join(os.getcwd(),\"3pt_zero.h5\")\n",
>>>>>>> 7347fca4b269832bedf839a8c10fe0d70f3897f4
    "out_file['3pt_tsep15'] = os.path.join(os.getcwd(),\"3pt_tsep15.h5\")\n",
    "out_file['3pt_tsep17'] = os.path.join(os.getcwd(),\"3pt_tsep17.h5\")\n",
    "out_file['3pt_tsep19'] = os.path.join(os.getcwd(),\"3pt_tsep19.h5\")\n",
    "out_file['3pt_tsep21'] = os.path.join(os.getcwd(),\"3pt_tsep21.h5\")\n",
    "\n",
    "\n",
    "# TODO this needs to be in a loop, but not working with external module concat_dsets\n",
    "# for corr in dset_replace_patterns.keys():\n",
    "# concat_dsets(data_file_list[0:20], out_file['proton_all'], dset_replace_patterns=dset_replace_patterns['proton'],overwrite=False,write_unpaired_dsets=True)\n",
    "# concat_dsets(data_file_list[0:4], out_file['pion'], dset_replace_patterns=dset_replace_patterns['pion'],overwrite=False,write_unpaired_dsets=False)\n",
    "# concat_dsets(data_file_list[0:4], out_file['pion'], dset_replace_patterns=dset_replace_patterns['pion_SP'],overwrite=False,write_unpaired_dsets=True)\n",
    "# concat_dsets(data_file_list[0:4], out_file['proton_SP'], dset_replace_patterns=dset_replace_patterns['proton_SP'],overwrite=False,write_unpaired_dsets=True)\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "concat_dsets(data_file_list[0:4], out_file['3pt'], dset_replace_patterns=dset_replace_patterns['gA'],overwrite=True,write_unpaired_dsets=True)\n",
=======
    "concat_dsets(data_file_list[0:2], out_file['3pt'], dset_replace_patterns=dset_replace_patterns['gA'],overwrite=False,write_unpaired_dsets=True)\n",
>>>>>>> 7347fca4b269832bedf839a8c10fe0d70f3897f4
=======
    "concat_dsets(data_file_list[0:2], out_file['3pt'], dset_replace_patterns=dset_replace_patterns['gA'],overwrite=False,write_unpaired_dsets=True)\n",
>>>>>>> 7347fca4b269832bedf839a8c10fe0d70f3897f4
    "concat_dsets(data_file_list[0:4], out_file['3pt_tsep15'], dset_replace_patterns=dset_replace_patterns['3pt_tsep15'],overwrite=False,write_unpaired_dsets=True)\n",
    "concat_dsets(data_file_list[0:4], out_file['3pt_tsep17'], dset_replace_patterns=dset_replace_patterns['3pt_tsep17'],overwrite=False,write_unpaired_dsets=True)\n",
    "concat_dsets(data_file_list[0:4], out_file['3pt_tsep19'], dset_replace_patterns=dset_replace_patterns['3pt_tsep19'],overwrite=False,write_unpaired_dsets=True)\n",
    "concat_dsets(data_file_list[0:4], out_file['3pt_tsep21'], dset_replace_patterns=dset_replace_patterns['3pt_tsep21'],overwrite=False,write_unpaired_dsets=True)\n",
    "\n",
    "# streams = {\n",
    "#     'E7' : ['0','a','b','c']\n",
    "# }\n",
    "# for i_s, s in enumerate(streams[ens]):\n",
    "#     f_in = h5.open_file(ens+'_'+s+'/'+data_dir+'/avg/'+ens+'_'+s+'_avg_srcs'+srcs[ens]+'.h5')\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mom_avg(h5_data,state,mom_lst,weights=False):\n",
    "    '''\n",
    "    perform a momentum average of a state from an open h5 file\n",
    "    data file is assumed to be of shape [Nt,Nz,Ny,Nx,[re,im]]\n",
    "    data_mom = h5_data[state][:,qz,qy,qx]\n",
    "    '''\n",
    "    d_lst = []\n",
    "    # w = []\n",
    "    for mom in mom_lst:\n",
    "        qx,qy,qz = mom['momentum']\n",
    "        # w.append(mom['weight'])\n",
    "        #print(state)\n",
    "        d_lst.append(h5_data[state][:,qz,qy,qx])\n",
    "    d_lst = np.array(d_lst)\n",
    "    w = np.array(w)\n",
    "    if weights:\n",
    "        for wi,we in enumerate(w):\n",
    "            d_lst[wi] = we*d_lst[wi]\n",
    "        d_avg = np.sum(d_lst,axis=0) / np.sum(w)\n",
    "    else:\n",
    "        d_avg = np.mean(d_lst,axis=0)\n",
    "    return d_avg\n",
    "# mom_avg('/home/gbradley/c51_corr_analysis/tests/data/C13/C13-b_5178.ama.h5', state, mom_lst)\n",
    "\n",
    "mom_lst = []\n",
    "for qx in range(-2,3):\n",
    "    for qy in range(-2,3):\n",
    "        for qz in range(-2,3):\n",
    "            if qx**2 + qy**2 + qz**2 <= 5:\n",
    "                mom_lst.append('qz'+str(qz)+'_qy'+str(qy)+'_qx'+str(qx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E7-b_232 A3 13\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-157-c9d7dff54856>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpack_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma3_7_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0ma3_neg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpack_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma3_7_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0munpack_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma3_11_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0munpack_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma3_13_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0munpack_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma3_14_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma3_neg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma3_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "def unpack_tuple(data):\n",
    "    # if type(data[0]) is tuple:\n",
    "    for i in range(len(data[0])):\n",
    "        obj_array = []\n",
    "        for k in range(len(data)):\n",
    "            obj_array.append(data[k][i])\n",
    "    return obj_array\n",
    "\n",
    "ens = 'E7'\n",
    "ens_s = ens+'-b_232'\n",
    "t_seps  = [13,15,17,19,21]\n",
    "# f_out = h5.open_file('testing_charges.h5','w')\n",
    "# f_in = h5.open_file('/home/gbradley/c51_corr_analysis/tests/data/E7/E7-%(STREAM)s_%(CFG)s.ama.h5')\n",
    "f_in = h5.open_file('/home/gbradley/c51_corr_analysis/tests/data/E7/'+ens_s+'.ama.h5')\n",
    "try:\n",
    "    f_out.create_group('/'+ens_s,'A3',createparents=True)\n",
    "    f_out.create_group('/'+ens_s,'V4',createparents=True)\n",
    "except:\n",
    "    pass\n",
    "path = '/3pt_tsep%(DT)s/NUCL_%(FS)s_MIXED_NONREL_l0_g%(GAMMA)s/src10.0_snk10.0/qz+0_qy+0_qx+0/E7.b_232/AMA'\n",
    "for dt in t_seps:\n",
    "    tmp_path = path % {'FS':'U','DT':dt,'GAMMA':'7'}\n",
    "    if tmp_path in f_in.get_node('/'):\n",
    "        print(ens_s,'A3',dt) \n",
    "\n",
    "# ''' 4: axial;   g_x g_5\n",
    "# 13: axial;  -g_y g_5\n",
    "# 11: axial;   g_z g_5\n",
    "# 7: axial;  -g_t g_5''' \n",
    "\n",
    "    \n",
    "#       pos parity ?\n",
    "        a3_7  = f_in.get_node(path % {'FS':'U','DT':dt,'GAMMA':'7'}).read()\n",
    "        a3_11 = f_in.get_node(path % {'FS':'U','DT':dt,'GAMMA':'11'}).read()\n",
    "        a3_13 = f_in.get_node(path % {'FS':'U','DT':dt,'GAMMA':'13'}).read()\n",
    "        a3_14 = f_in.get_node(path % {'FS':'U','DT':dt,'GAMMA':'14'}).read()\n",
    "        # print(a3_4)\n",
    "        a3_pos = []\n",
    "        for x in range(0,len(unpack_tuple(a3_7))):\n",
    "            a3_pos.append(unpack_tuple(a3_7)[x] - unpack_tuple(a3_11)[x] + unpack_tuple(a3_13)[x] - unpack_tuple(a3_14)[x] )\n",
    "        # print(a3_pos)\n",
    "\n",
    "        #neg parity ?\n",
    "        a3_7_n  = f_in.get_node(path % {'FS':'D','DT':dt,'GAMMA':'7'}).read()\n",
    "        a3_11_n = f_in.get_node(path % {'FS':'D','DT':dt,'GAMMA':'11'}).read()\n",
    "        a3_13_n = f_in.get_node(path % {'FS':'D','DT':dt,'GAMMA':'13'}).read()\n",
    "        a3_14_n = f_in.get_node(path % {'FS':'D','DT':dt,'GAMMA':'14'}).read()\n",
    "        # print(a3_4)\n",
    "        a3_neg = []\n",
    "        for x in range(0,len(unpack_tuple(a3_7_n))):\n",
    "            a3_neg.append(unpack_tuple(a3_7_n)[x] - unpack_tuple(a3_11_n)[x] + unpack_tuple(a3_13_n)[x] - unpack_tuple(a3_14_n)[x] )\n",
    "        np.concatenate(np.asarray(a3_neg),np.asarray(a3_pos))\n",
    "        \n",
    "\n",
    "        # a3 = []\n",
    "        # for x in range(0,len(a3_pos)):\n",
    "        #     a3.append(a3_pos[x]+a3_neg[x])\n",
    "        #     print(a3)\n",
    "    #         # print(0.5* np.sum(a3,axis=0))\n",
    "    #     f_out.create_array('/'+ens_s+'/A3','tsep_'+str(dt),a3_neg)\n",
    "    # #     # print(a3.shape)\n",
    "    #     # f_out.flush()\n",
    "    #     f_out.close()\n",
    "        # print(unpack_tuple(a3_4))\n",
    "\n",
    "        # unpack_tuple(a3_4) - unpack_tuple(a3_7) + unpack_tuple(a3_11) - unpack_tuple(a3_14)\n",
    "    # # neg parity ?\n",
    "    # a3  += f_in.get_node(path % {'FS':'D','DT':dt,'GAMMA':'4'}).read()\n",
    "    # a3 -= f_in.get_node(path % {'FS':'D' ,'DT':dt,'GAMMA':'7'}).read()\n",
    "    # a3 += f_in.get_node(path % {'FS':'D' ,'DT':dt,'GAMMA':'11'}).read()\n",
    "    # a3 -= f_in.get_node(path % {'FS':'D' ,'DT':dt,'GAMMA':'14'}).read()\n",
    "    # a3 = np.sum(a3,axis=4)\n",
    "    # a3 = np.sum(a3,axis=3)\n",
    "    # a3 = np.sum(a3,axis=2)\n",
    "    # a3 = 0.5 * a3\n",
    "    # f_out.create_array('/'+ens_s+'/A3','tsep_'+str(dt),a3)\n",
    "    # print(a3.shape)\n",
    "    # f_out.flush()\n",
    "    \n",
    "# for corr in ['proton']:\n",
    "#     for parity in ['','_SP']:\n",
    "#         print(corr,parity)\n",
    "#         for i_s,s in enumerate(streams[ens]):\n",
    "#             f_in = h5.open_file(ens+'_'+s+'/'+data_dir+'/avg/'+ens+'_'+s+'_avg_srcs'+srcs[ens]+'.h5')\n",
    "#             if s == streams[ens][0]:\n",
    "#                 su = f_in.get_node('/'+val[ens]+'/spec/'+spec[ens]+'/'+corr+parity+'/px0_py0_pz0/spin_up').read()\n",
    "#                 sd = f_in.get_node('/'+val[ens]+'/spec/'+spec[ens]+'/'+corr+parity+'/px0_py0_pz0/spin_dn').read()\n",
    "#                 cs = f_in.get_node('/'+val[ens]+'/spec/'+spec[ens]+'/'+corr+parity+'/px0_py0_pz0/cfgs_srcs').read()\n",
    "#             else:\n",
    "#                 tmp_su = f_in.get_node('/'+val[ens]+'/spec/'+spec[ens]+'/'+corr+parity+'/px0_py0_pz0/spin_up').read()\n",
    "#                 tmp_sd = f_in.get_node('/'+val[ens]+'/spec/'+spec[ens]+'/'+corr+parity+'/px0_py0_pz0/spin_dn').read()\n",
    "#                 tmp_cs = f_in.get_node('/'+val[ens]+'/spec/'+spec[ens]+'/'+corr+parity+'/px0_py0_pz0/cfgs_srcs').read()\n",
    "#                 tmp_cs[:,0] += i_s * cs_offset[ens]\n",
    "#                 su = np.concatenate((su,tmp_su),axis=0)\n",
    "#                 sd = np.concatenate((sd,tmp_sd),axis=0)\n",
    "#                 cs = np.concatenate((cs,tmp_cs),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns = [\"nucleon\", \"current\", \"tsep\", \"cfg\", \"t\", \"isospin\", \"parity\", \"spin\", \"corr\"]\n",
    "columns = [\"tsep\", \"quark\", \"l\", \"g\", \"src\", \"snk\",\"qz\",\"qy\",\"qx\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-08-24 15:48:53,566|lqcd correlator analysis@INFO] Locating all dsets of h5 file `/home/gbradley/c51_corr_analysis/tests/data/C13/C13-b_4002.ama.h5`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tsep</th>\n",
       "      <th>quark</th>\n",
       "      <th>l</th>\n",
       "      <th>g</th>\n",
       "      <th>src</th>\n",
       "      <th>snk</th>\n",
       "      <th>qz</th>\n",
       "      <th>qy</th>\n",
       "      <th>qx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>+0</td>\n",
       "      <td>+0</td>\n",
       "      <td>+0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>+0</td>\n",
       "      <td>+0</td>\n",
       "      <td>+0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>+0</td>\n",
       "      <td>+0</td>\n",
       "      <td>+0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>+0</td>\n",
       "      <td>+0</td>\n",
       "      <td>+0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>+0</td>\n",
       "      <td>+0</td>\n",
       "      <td>+0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tsep quark  l  g  src  snk  qz  qy  qx\n",
       "0     8     D  0  0  5.0  5.0  +0  +0  +0\n",
       "1     8     D  0  0  5.0  5.0  +0  +0  +0\n",
       "2     8     D  0  0  5.0  5.0  +0  +0  +0\n",
       "3     8     D  0  0  5.0  5.0  +0  +0  +0\n",
       "4     8     D  0  0  5.0  5.0  +0  +0  +0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frames = []\n",
    "\n",
    "with h5py.File(h5fname, \"r\") as h5f:\n",
    "    dsets = get_dsets(h5f)\n",
    "    # print(dsets)\n",
    "\n",
    "    for key, dset in dsets.items():\n",
    "        match = re.search(pattern, key)\n",
    "        if match:\n",
    "            info = match.groupdict()\n",
    "            # print(info)\n",
    "\n",
    "            # nucleon_parity = info.pop(\"parity\").split(\"_\")\n",
    "            g = info.pop(\"g\").split(\"_\")\n",
    "            # print(g)\n",
    "            info[\"g\"] = g[0]\n",
    "            # info[\"nucleon\"] = nucleon_parity[0]\n",
    "            # info[\"parity\"] = -1 if len(nucleon_parity) == 2 else 1\n",
    "            \n",
    "            # isospin = info.pop(\"isospin\")\n",
    "            # info[\"isospin\"] = 1 if isospin == \"UU\" else -1            \n",
    "\n",
    "            # current_key = key.replace(\"cfgs_srcs\", \"local_curr\")\n",
    "            curr_dset = h5f[key]\n",
    "            # print(curr_dset)\n",
    "            # print(curr_dset[0])\n",
    "            # print(curr_dset[0][0])\n",
    "\n",
    "            cfgs = dset[:]\n",
    "            # print(cfgs)\n",
    "            # print(cfgs[0])\n",
    "            corr = (\n",
    "                curr_dset[:][0] if info[\"g\"] in [\"g1\",\"g2\",\"g4\",\"g8\"] else curr_dset[:][1]\n",
    "            )\n",
    "            \n",
    "#             # print(corr)\n",
    "            ts = range(len(corr))\n",
    "#             # print(ts)\n",
    "#             # ts = range(corr.shape[-1])\n",
    "\n",
    "            tmp_df = (\n",
    "                pd.DataFrame(index=cfgs, columns=ts, data=corr)\n",
    "                .unstack()\n",
    "                .reset_index()\n",
    "                .rename(columns={\"level_0\": \"t\", \"level_1\": \"cfg\", 0: \"corr\"})\n",
    "            )\n",
    "            # print(tmp_df)\n",
    "            for key, val in info.items():\n",
    "                tmp_df[key] = val\n",
    "            data_frames.append(tmp_df.astype({\"tsep\": int}))\n",
    "\n",
    "\n",
    "\n",
    "df = pd.concat(\n",
    "    data_frames, \n",
    "    ignore_index=True, \n",
    ").reindex(columns, axis=1).sort_values(columns).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nucleon</th>\n",
       "      <th>current</th>\n",
       "      <th>tsep</th>\n",
       "      <th>cfg</th>\n",
       "      <th>t</th>\n",
       "      <th>isospin</th>\n",
       "      <th>parity</th>\n",
       "      <th>corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>proton</td>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>7.123843e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proton</td>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.496932e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>proton</td>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.118381e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>proton</td>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-8.362174e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>proton</td>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>9.552208e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  nucleon current  tsep   cfg  t  isospin  parity          corr\n",
       "0  proton      A3     3  78.0  0       -1      -1  7.123843e-10\n",
       "1  proton      A3     3  78.0  0       -1       1 -5.496932e-10\n",
       "2  proton      A3     3  78.0  0        1      -1  1.118381e-09\n",
       "3  proton      A3     3  78.0  0        1       1 -8.362174e-10\n",
       "4  proton      A3     3  78.0  1       -1      -1  9.552208e-10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spin_avg_df = df.groupby(\n",
    "    [\"nucleon\", \"current\", \"tsep\", \"cfg\", \"t\", \"isospin\", \"parity\"], as_index=False\n",
    ")[\"corr\"].mean()\n",
    "\n",
    "spin_avg_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nucleon</th>\n",
       "      <th>current</th>\n",
       "      <th>tsep</th>\n",
       "      <th>cfg</th>\n",
       "      <th>t</th>\n",
       "      <th>isospin</th>\n",
       "      <th>corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>proton</td>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-6.310388e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proton</td>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-9.772991e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>proton</td>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-6.853185e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>proton</td>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.990430e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>proton</td>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-6.418973e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  nucleon current  tsep   cfg  t  isospin          corr\n",
       "0  proton      A3     3  78.0  0       -1 -6.310388e-10\n",
       "1  proton      A3     3  78.0  0        1 -9.772991e-10\n",
       "2  proton      A3     3  78.0  1       -1 -6.853185e-10\n",
       "3  proton      A3     3  78.0  1        1 -5.990430e-10\n",
       "4  proton      A3     3  78.0  2       -1 -6.418973e-10"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = spin_avg_df.copy()\n",
    "tmp[\"corr\"] *= tmp[\"parity\"]\n",
    "spin_parity_avg_df = tmp.groupby(\n",
    "    [\"nucleon\", \"current\", \"tsep\", \"cfg\", \"t\", \"isospin\",  ], as_index=False\n",
    ")[[\"corr\"]].mean()\n",
    "\n",
    "spin_parity_avg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nucleon</th>\n",
       "      <th>current</th>\n",
       "      <th>tsep</th>\n",
       "      <th>cfg</th>\n",
       "      <th>t</th>\n",
       "      <th>corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>proton</td>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.462603e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proton</td>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.627543e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>proton</td>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.859727e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>proton</td>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4.257450e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>proton</td>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.371521e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  nucleon current  tsep   cfg  t          corr\n",
       "0  proton      A3     3  78.0  0 -3.462603e-10\n",
       "1  proton      A3     3  78.0  1  8.627543e-11\n",
       "2  proton      A3     3  78.0  2  2.859727e-10\n",
       "3  proton      A3     3  78.0  3  4.257450e-11\n",
       "4  proton      A3     3  84.0  0  5.371521e-10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = spin_parity_avg_df.copy()\n",
    "tmp[\"corr\"] *= tmp[\"isospin\"]\n",
    "isospin_spin_parity_avg_df = (\n",
    "    tmp.groupby([\"nucleon\", \"current\", \"tsep\", \"cfg\",  \"t\"], as_index=False)[\"corr\"]\n",
    "    .sum()\n",
    ")\n",
    "isospin_spin_parity_avg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_data(arg):\n",
    "    corr_avg = gv.dataset.avg_data(\n",
    "        arg.pivot(index=\"cfg\", columns=\"t\", values=\"corr\").values\n",
    "    )\n",
    "    return pd.Series(corr_avg)\n",
    "\n",
    "\n",
    "group = isospin_spin_parity_avg_df.groupby([\"nucleon\", \"current\", \"tsep\"])\n",
    "corr_df = (\n",
    "    group.apply(avg_data)\n",
    "    .reset_index(level=-1)\n",
    "    .rename(columns={\"level_3\": \"t\", 0: \"corr\"})\n",
    "    .reset_index()\n",
    "    .set_index([\"nucleon\", \"current\", \"tsep\", \"t\"])\n",
    ")\n",
    "# # print(corr_df)\n",
    "# corr_out = corr_df.to_dict(orient='tight')\n",
    "# # print(corr_out)\n",
    "# test = corr_df.loc[('proton', 'A3'),'corr']\n",
    "# test_src = \n",
    "# out = test.to_dict()\n",
    "# ydict = {tag: val for tag,val in out.items() if isinstance(tag,tuple)}\n",
    "# # print(ydict)\n",
    "# t_snk = list()\n",
    "# for item in out.keys():\n",
    "#     if item[0] not in t_snk:\n",
    "#         t_snk.append(item[0])\n",
    "# print(t_snk)\n",
    "# import fitter.corr_functions as cf \n",
    "# c3 = cf.C_3pt(tag='proton',ydata_3pt=ydict)\n",
    "# print(c3)\n",
    "# # # print(out)\n",
    "# # list(out.keys())\n",
    "# # [i[0] for i in out.keys()]\n"
   ]
  },
  {
<<<<<<< HEAD
<<<<<<< HEAD
=======
=======
>>>>>>> 7347fca4b269832bedf839a8c10fe0d70f3897f4
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "t_sink keys must be integers.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-47350a447a5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_sink\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_sink\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"t_sink keys must be integers.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: t_sink keys must be integers."
     ]
    }
   ],
   "source": [
    "for t_sink in out.keys():\n",
    "    print(t_sink)\n",
    "    if not isinstance(t_sink, int):\n",
    "        raise TypeError(\"t_sink keys must be integers.\")\n",
    "    if nt is None:\n",
    "        try:\n",
    "            np.unique([len(arr) for arr in out.values()]).item()\n",
    "        except ValueError as _:\n",
    "            raise ValueError(\"Values in ydict must have same length.\")"
   ]
  },
  {
<<<<<<< HEAD
>>>>>>> 7347fca4b269832bedf839a8c10fe0d70f3897f4
=======
>>>>>>> 7347fca4b269832bedf839a8c10fe0d70f3897f4
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
<<<<<<< HEAD
=======
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NUCL: nucleon\n",
    "U: quark bilinear operator inserted on up-quark; D will be used for down-quark\n",
    "MIXED: \"mixed\" type of spin projection is used\n",
    "NONREL: non-relativistic proton is used\n",
    "l0:  when inserting the quark bilinear oprator, the separation of the quarks of the bilinear operator is zero (local operator); you might see some l1 (quark bilinear operator separated by 1 lattice unit) data as well\n",
    "g13: the gamma matrix of the quark bilinear operator is \"13\" in Chroma convention. Page 6 and 7 of the attached pdf shows the Chroma gamma matrix convention and its indexing; their indexing is summarized below:\n",
    " \n",
    "0: scalar; I\n",
    "15: pseudoscalar; g_5\n",
    "1: vector;  g_x\n",
    "2: vector;  g_y\n",
    "4: vector;  g_z\n",
    "8: vector;  g_t\n",
    "14: axial;   g_x g_5\n",
    "13: axial;  -g_y g_5\n",
    "11: axial;   g_z g_5\n",
    "7: axial;  -g_t g_5\n",
    "9: tensor;  g_x g_t\n",
    "10: tensor;  g_y g_t\n",
    "12: tensor;  g_z g_t\n",
    "3: tensor;  g_x g_y\n",
    "6: tensor;  g_y g_z\n",
    "5: tensor;  g_x g_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_baryon_tag(datatag):\n",
    "    ''' Given a datatag, return dict with keys to pass into fitter  '''\n",
    "    datatag_split = datatag.split('/')\n",
    "    corr_type     = datatag_split[0]\n",
    "    tsep          = int(corr_type.split('_tsep')[1])\n",
    "    buffer        =  datatag_split[1]\n",
    "    channel       = buffer.split('_')[0]\n",
    "    quark_ins       = buffer.split('_')[1]\n",
    "    spin_proj       = buffer.split('_')[2]\n",
    "    quark_sep       = buffer.split('_')[3]\n",
    "    gamma           = buffer.split('_')[4] #gamma matrix of quark bilinear operator in the CHROMA convention , value accessed via dict\n",
    "    src_snk_sep     = datatag_split[2]\n",
    "    mom         = datatag_split[3]\n",
    "    mom0       = mom.split('_')[0]\n",
    "    mom1       = mom.split('_')[1]\n",
    "    mom2       = mom.split('_')[2]\n",
    "    momentum        = (mom0,mom1,mom2)\n",
    "    config   = datatag_split[4]\n",
    "\n",
    "    data_dict = dict()\n",
    "    data_dict['corr_type']   = corr_type\n",
    "    data_dict['tsep']        = tsep\n",
    "    data_dict['buffer']      = buffer\n",
    "    data_dict['channel']     = channel\n",
    "    data_dict['quark_ins']   = quark_ins\n",
    "    data_dict['spin_proj']   = spin_proj\n",
    "    data_dict['quark_sep']   = quark_sep\n",
    "    data_dict['gamma']       = gamma\n",
    "    data_dict['src_snk_sep'] = src_snk_sep\n",
    "    data_dict['mom']         = momentum\n",
    "    data_dict['config']      = config\n",
    "    return data_dict\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'corr_type': '3pt_tsep12',\n",
       " 'tsep': 12,\n",
       " 'buffer': 'NUCL_D_MIXED_NONREL_l0_g0',\n",
       " 'channel': 'NUCL',\n",
       " 'quark_ins': 'D',\n",
       " 'spin_proj': 'MIXED',\n",
       " 'quark_sep': 'NONREL',\n",
       " 'gamma': 'l0',\n",
       " 'src_snk_sep': 'src5.0_snk5.0',\n",
       " 'mom': ('qz+0', 'qy+0', 'qx+0'),\n",
       " 'config': 'C13.b_5682'}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "parse_baryon_tag(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_2pt_spec(params,dsets,h5_file =None,collect=False):\n",
    "    params = dict(params)\n",
    "    params['buffer'] = pion \n",
    "    \n",
    "    "
   ]
  },
  {
>>>>>>> 7347fca4b269832bedf839a8c10fe0d70f3897f4
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"tsep\", \"quark\", \"l\", \"g\", \"src\", \"snk\",\"qz\",\"qy\",\"qx\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-08-16 20:27:20,527|lqcd correlator analysis@INFO] Locating all dsets of h5 file `/home/gbradley/c51_corr_analysis/tests/data/C13/C13-b_5682.ama.h5`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tsep</th>\n",
       "      <th>g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tsep</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tsep   g\n",
       "tsep   NaN NaN\n",
       "g      NaN NaN"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frames = []\n",
    "\n",
    "with h5py.File(file, \"r\") as h5f:\n",
    "    dsets = get_dsets(h5f)\n",
    "    # print(dsets)\n",
    "    for key, dset in dsets.items():\n",
    "        match = re.search(pattern, string)\n",
    "        if match:\n",
    "            info = match.groupdict()\n",
    "            # print(info)\n",
    "#             corr = info.pop(\"tsep\")\n",
    "\n",
    "            quark = info.pop(\"quark\")\n",
    "            # print(quark)\n",
    "            info[\"quark\"] = quark[0]\n",
    "# #             # info[\"parity\"] = -1 if len(nucleon_parity) == 2 else 1\n",
    "            \n",
    "            gamma = info.pop(\"g\")\n",
    "            if gamma in [\"g1\",\"g2\",\"g4\",\"g8\"]:\n",
    "                info[\"gamma\"] = \"vector\"\n",
    "            elif gamma in [\"g0\"]:\n",
    "                info[\"gamma\"] = \"scalar\"\n",
    "            elif gamma in [\"g5\"]:\n",
    "                info[\"gamma\"] = \"pseudoscalar\"\n",
    "            elif gamma in [\"g14\",\"g13\",\"g11\",\"g7\"]:\n",
    "                info[\"gamma\"] = \"axial\"\n",
    "            elif gamma in [\"g14\",\"g13\",\"g11\",\"g7\"]:\n",
    "                info[\"gamma\"] = \"axial\"\n",
    "            elif gamma in [\"g9\",\"g10\",\"g12\",\"g3\",\"g6\",\"g5\"]:\n",
    "                info[\"gamma\"] = \"tensor\"\n",
    "\n",
    "            # current_key = key.replace(\"g\", \"\")\n",
    "            curr_dset = h5f[key]\n",
    "\n",
    "            cfgs = dset[:]\n",
    "            corr = (\n",
    "                curr_dset[()].real \n",
    "                # if info[\"current\"] in [\"V4\"] else curr_dset[()].imag\n",
    "            )\n",
    "            # print(corr.shape[-1])\n",
    "            ts = range(corr.shape[-1])\n",
    "            # print(ts)\n",
    "            tmp_df = (\n",
    "                pd.DataFrame(index=cfgs, columns=ts, data=corr)\n",
    "                .unstack()\n",
    "                .reset_index()\n",
    "                .rename(columns={\"level_0\": \"tsep\", \"level_1\": \"cfg\", 0: \"corr\"})\n",
    "            )\n",
    "            # data_frames = {}\n",
    "            ydict = {}\n",
    "            for key, val in info.items():\n",
    "                tmp_df[key] = val\n",
    "            data_frames.append(tmp_df.astype({\"tsep\": int}))\n",
    "            # print(data_frames)\n",
    "\n",
    "\n",
    "df = pd.concat(\n",
    "    data_frames, \n",
    "    ignore_index=True, \n",
    ").reindex(columns, axis=1).sort_values(columns).reset_index(drop=True)\n",
    "\n",
    "# df.head()\n",
    "# print(df.keys())\n",
    "# for 'tsep' in df.keys():\n",
    "#     if not isinstance(tsep, int):\n",
    "#                 raise TypeError(\"t_sink keys must be integers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          12\n",
      "1          12\n",
      "2          12\n",
      "3          12\n",
      "4          12\n",
      "           ..\n",
      "3729211    12\n",
      "3729212    12\n",
      "3729213    12\n",
      "3729214    12\n",
      "3729215    12\n",
      "Name: tsep, Length: 3729216, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import corr_functions as cf \n",
    "print(df.tsep)\n",
    "ydict = {tag: val for tag, val in df.items() if isinstance(tag, int)}\n",
    "ydict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## statistical average ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_data(arg):\n",
    "    corr_avg = gvar.dataset.avg_data(\n",
    "        arg.pivot(index=\"cfg\", columns=\"t\", values=\"corr\").values\n",
    "    )\n",
    "    return pd.Series(corr_avg)\n",
    "\n",
    "\n",
    "group = isospin_spin_parity_avg_df.groupby([\"nucleon\", \"current\", \"tsep\"])\n",
    "corr_df = (\n",
    "    group.apply(avg_data)\n",
    "    .reset_index(level=-1)\n",
    "    .rename(columns={\"level_3\": \"t\", 0: \"corr\"})\n",
    "    .reset_index()\n",
    "    .set_index([\"nucleon\", \"current\", \"tsep\", \"t\"])\n",
    ")\n",
    "\n",
    "corr_df.head()"
   ]
<<<<<<< HEAD
=======
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## momentum average ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mom_avg(h5_data,state,mom_lst,weights=False):\n",
    "    '''\n",
    "    perform a momentum average of a state from an open h5 file\n",
    "    data file is assumed to be of shape [Nt,Nz,Ny,Nx,[re,im]]\n",
    "    data_mom = h5_data[state][:,qz,qy,qx]\n",
    "    '''\n",
    "    d_lst = []\n",
    "    w = []\n",
    "    for mom in mom_lst:\n",
    "        qx,qy,qz = mom['momentum']\n",
    "        # w.append(mom['weight'])\n",
    "        #print(state)\n",
    "        d_lst.append(h5_data[state][:,qz,qy,qx])\n",
    "    d_lst = np.array(d_lst)\n",
    "    w = np.array(w)\n",
    "    if weights:\n",
    "        for wi,we in enumerate(w):\n",
    "            d_lst[wi] = we*d_lst[wi]\n",
    "        d_avg = np.sum(d_lst,axis=0) / np.sum(w)\n",
    "    else:\n",
    "        d_avg = np.mean(d_lst,axis=0)\n",
    "    return d_avg\n",
    "# mom_avg('/home/gbradley/c51_corr_analysis/tests/data/C13/C13-b_5178.ama.h5', state, mom_lst)\n",
    "\n",
    "mom_lst = []\n",
    "for qx in range(-2,3):\n",
    "    for qy in range(-2,3):\n",
    "        for qz in range(-2,3):\n",
    "            if qx**2 + qy**2 + qz**2 <= 5:\n",
    "                mom_lst.append('qz'+str(qz)+'_qy'+str(qy)+'_qx'+str(qx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
>>>>>>> 7347fca4b269832bedf839a8c10fe0d70f3897f4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
